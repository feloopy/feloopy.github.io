name: Fetch Feloopy Stats

on:
  schedule:
    - cron: '0 0 * * *'        # daily at 00:00 UTC
  workflow_dispatch:

jobs:
  update-stats:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          pip install requests beautifulsoup4 pypistats pypinfo

      - name: Fetch stats & build JSON
        run: |
          python << 'EOF'
          import json, datetime, subprocess, re
          import requests
          from bs4 import BeautifulSoup

          stats = {}

          # 1. Daily/weekly/monthly downloads via PyPI Stats API
          r = requests.get('https://pypistats.org/api/packages/feloopy/recent').json()
          d = r.get('data', {})
          stats['day']   = d.get('last_day', 0)
          stats['week']  = d.get('last_week', 0)
          stats['month'] = d.get('last_month', 0)            # :contentReference[oaicite:1]{index=1}

          # 2. Total downloads via Shields.io badge JSON
          shield = requests.get('https://img.shields.io/pypi/dt/feloopy.json').json()
          v = re.sub(r'\D','', str(shield.get('value','')))
          stats['total'] = int(v) if v.isdigit() else 0     # 

          # 3. GitHub stars (public endpoint)
          gh = requests.get("https://api.github.com/repos/feloopy/feloopy").json()
          stats['stars'] = gh.get('stargazers_count', 0)     # 

          # 4. YouTube subs & views by scraping ytInitialData JSON
          html = requests.get('https://www.youtube.com/@feloopy/about').text
          m = re.search(r'window\["ytInitialData"\] = (.*?);\s*</script>', html, re.S)
          if m:
              jd = json.loads(m.group(1))
              hdr = jd['header']['c4TabbedHeaderRenderer']
              stats['youtube_subs']  = hdr['subscriberCountText']['simpleText']
              stats['youtube_views'] = hdr['viewCountText']['simpleText']
          else:
              stats['youtube_subs'] = stats['youtube_views'] = 'n/a'  # :contentReference[oaicite:2]{index=2}

          # 5. Downloads by country via pypinfo CLI (BigQuery free tier)
          #     note: -j and -l must come before the project name
          out = subprocess.check_output([
            'pypinfo', '-j', '-l', '200', 'feloopy', 'country'
          ])
          stats['by_country'] = json.loads(out)['rows']        # :contentReference[oaicite:3]{index=3}

          # 6. Append daily GitHub stars history
          hist_path = 'stars_history.json'
          today = datetime.date.today().isoformat()
          try:
              history = json.load(open(hist_path))
          except FileNotFoundError:
              history = {}
          history[today] = stats['stars']
          with open(hist_path,'w') as f:
              json.dump(history, f, indent=2)

          stats['fetched_at'] = datetime.datetime.utcnow().isoformat()+'Z'
          with open('stats.json','w') as f:
              json.dump(stats, f, indent=2)
          EOF

      - name: Commit & push
        run: |
          git config user.name github-actions
          git config user.email actions@github.com
          git add stats.json stars_history.json
          git diff --staged --quiet || git commit -m "Update stats.json"
          git push
